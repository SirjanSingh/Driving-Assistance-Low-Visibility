# DriveGuard AI â€“ Low-Visibility Driving Assistance SystemÂ Â 
### *Edge AI â€¢ YOLOv12-s â€¢ Raspberry Pi â€¢ Real-Time Distance Estimation*

![banner](images/banner.jpg)
*(Replace with your banner image inside /images)*

---

## OverviewÂ Â 
DriveGuard AI is an **Edge-powered intelligent driving assistance system** built for **fog, night, rain, dust, and low-visibility scenarios**.Â Â 
It performs **real-time object detection, distance estimation, and safety alerts** using:

* **YOLOv12-s** (custom trained)
* **Edge Impulse** optimized quantized model
* **Raspberry Pi** deployment
* Full **camera calibration** ($f_x, f_y, c_x, c_y$, height, tilt)

Runs fully **offline** on edge devices $\rightarrow$ ideal for on-road safety.

---

# ğŸ“¸ ScreenshotsÂ Â 

### Detection ExamplesÂ Â 
![detection1](images/detection1.jpg)Â Â 
![detection2](images/detection2.jpg)

### Alerts + Distance OverlayÂ Â 
![alerts](images/alerts.jpg)

---

# Key FeaturesÂ Â 

## Core AI CapabilitiesÂ Â 
* **YOLOv12-s** optimized for fog & low-lightÂ Â 
* Multi-object detection: cars, pedestrians, animalsÂ Â 
* Fast inference on laptop + Raspberry PiÂ Â 
* Edge Impulse quantized accelerationÂ Â 

## ğŸ“ Advanced IntelligenceÂ Â 
* **Real-time calibrated distance estimation** $\leftarrow$ Crucial for safety!
* **Pinhole camera geometry** + tilt correctionÂ Â 
* Multi-object threat detectionÂ Â 
* On-screen bounding boxes + distance overlayÂ Â 

## Safety AlertsÂ Â 
* Windows $\rightarrow$ winsound beepÂ Â 
* Raspberry Pi $\rightarrow$ **GPIO buzzer alerts**Â Â 
* Warnings only when objects enter danger zoneÂ Â 

## Edge DeploymentÂ Â 
* Raspberry Pi 4 / 5 supportÂ Â 
* Raspberry Pi Camera Module v3 readyÂ Â 
* $<100\text{ms}$ inference using `.eim` modelÂ Â 

---

# ArchitectureÂ Â 

![architecture](images/architecture.png)Â Â 
*(Add your architecture diagram here)*

---

# Quick StartÂ Â 

## RequirementsÂ Â 
* Python 3.8+Â Â 
* Raspberry Pi (optional)Â Â 
* USB Webcam or Pi Camera v3Â Â 
* Edge Impulse accountÂ Â 
* YOLOv12-s weights (`yolov12s.pt`)

---

## âš™ï¸ InstallationÂ Â 

### 1. Clone repositoryÂ Â 
```bash
git clone [https://github.com/yourusername/Driving-Assistance-AI](https://github.com/yourusername/Driving-Assistance-AI)
cd Driving-Assistance-AI
```

### 2. Create virtual environment
```bash
python -m venv venv
source venv/Scripts/activateÂ  Â # Windows
source venv/bin/activateÂ  Â  Â  Â # Linux / Raspberry Pi
```

### 3. Install dependencies
```bash
pip install ultralytics opencv-python numpy
```

### 4. Add YOLO model
Place model file here:

/models/yolov12s.pt

### Run the System
On Laptop
```bash
python detect_video.py
```
On Raspberry Pi
```bash
python detect_video_pi.py
```

### Expected Console Output
```bash
Opening webcam at index 0...
âœ” Webcam opened successfully!
ALERT: Warning! Car ahead. Distance: 4.2m
```

Model Training (Edge Impulse)
Steps

Create a new project on Edge Impulse

Upload dataset (fog, night, rain, low-light)

Select Image â†’ Object Detection

Train YOLO-compatible model

Export as:

YOLO format (Python inference)

.eim format (Raspberry Pi optimized)

Full guide:

/docs/EDGE_IMPULSE_GUIDE.md

### Distance Estimation Formula
```bash
pixel_angle = atan((y_pixel - cy) / fy)
total_angle = camera_tilt_angle + pixel_angle
distance_Z = H / tan(total_angle)
```

### Performance
```bash
Metric                    Result
--------------------------------------------
FPS (Laptop)              30â€“60 FPS
FPS (Raspberry Pi 4)      10â€“20 FPS
Distance Accuracy         Â±5â€“10% after calibration
Model Size                ~20MB
Detection Targets         Cars, Pedestrians, Animals, Hazards

```
### Innovation

Works in fog, night & extreme low visibility

Hybrid YOLO + geometric distance system

Fully offline Edge AI with Raspberry Pi

Complete camera calibration pipeline

Real-time multi-object hazard alerts

Edge Impulse model compression â†’ high FPS

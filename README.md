# ğŸš— DriveGuard AI
### *Low-Visibility Driving Assistance System (Edge AI + YOLOv12s + Raspberry Pi)*

## ğŸ” Overview
DriveGuard AI is a real-time **on-edge driving assistance system** designed to help detect hazards in **fog, rain, night, and low-visibility environments**.

The system:
- Detects **cars, people, bikes, dogs, potholes**
- Runs **fully offline**
- Deploys on a **Raspberry Pi**
- Uses a **YOLOv12-s model optimized through Edge Impulse**
- Estimates distance using calibrated camera geometry and issues alerts

---

## ğŸ§  AI Workflow Summary

### 1ï¸âƒ£ Dataset Preparation
- Collected fog/low-visibility road images
- Annotated dataset in **YOLO format**
- Classes:

```
Car
Dog
Motorbike
People
Pothole
```

---

### 2ï¸âƒ£ YOLOv12-s Model Training (Locally)

Command used:
```
yolo train model=yolov12s.pt data=data.yaml imgsz=640 epochs=100
```

Exported for Edge Impulse:
```
yolo export model=best.pt format=onnx opset=12 simplify=True
```

---

### 3ï¸âƒ£ Edge Impulse Optimization & Deployment Conversion

Steps performed in Edge Impulse:

| Step | Status |
|------|--------|
| Created Project | âœ” |
| Uploaded dataset (images + labels) | âœ” |
| Added label map file | âœ” |
| Uploaded ONNX YOLO model | âœ” |
| Automatically validated model shape | âœ” |
| Generated ARM-ready `.eim` runtime bundle | âœ” |

Edge Impulse handled:
- Model quantization  
- Input/Output reshaping  
- ARM runtime packaging  
- Real-time deployment preview  

---

### 4ï¸âƒ£ Raspberry Pi Deployment

Downloaded generated model file:

```
sirjansingh-project-1-linux-armv7.eim
```

Installed runtime on Raspberry Pi:

```
pip install edge_impulse_linux
```

Run model with camera:

```
edge-impulse-linux-runner --model-file sirjansingh-project-1-linux-armv7.eim
```

Output:

- Displays bounding boxes in real-time  
- Provides web dashboard at:  
  ğŸ‘‰ `http://<raspberry-pi-ip>:4912`

---

## ğŸ“ Distance Estimation Formula

```
pixel_angle = atan((y - cy) / fy)
angle = camera_tilt + pixel_angle
distance = camera_height / tan(angle)
```

Used for hazard scoring and emergency alerts.

---

## ğŸ§ª Performance Summary

| Metric | Result |
|--------|--------|
| Raspberry Pi Runtime | ~10â€“20 FPS |
| Laptop Runtime | ~30â€“60 FPS |
| Requires Internet? | âŒ No (fully offline) |
| Model Format | `.onnx` â†’ `.eim` optimized |
| Accuracy improves in fog/night scenarios | âœ” |

---

## ğŸ›  Run the System

Laptop (raw YOLO inference):

```
python detect_video.py
```

Raspberry Pi (Edge Impulse optimized):

```
edge-impulse-linux-runner --model-file *.eim
```

---

## ğŸ¯ Key Features

- Fast on-device inference  
- Works in low visibility  
- Fully offline system  
- Distance + hazard alerts  
- Raspberry Pi compatible  

---

## ğŸš€ Future Improvements

- Lane detection  
- Speed tracking (SORT/DeepSORT)  
- LiDAR + Camera fusion  
- IR/thermal night mode  

---

## ğŸ‘¤ Author
**Ritigya Gupta**, 
**Sirjan Singh**, 
**Heeral Mandolia**

---

### Status: Prototype Complete âœ”
